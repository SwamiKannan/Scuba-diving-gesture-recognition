{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7213af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data_processor import names_list, create_final_features, create_labels_dict, train_test_extract,OHK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e331bcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH=os.path.join('data')\n",
    "SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732b198b",
   "metadata": {},
   "source": [
    "## 1. Get final feature array of shape (total sample_count X features X input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c03225",
   "metadata": {},
   "source": [
    "### Extract the list of file names in the format [action, sample_number, filename]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4562f",
   "metadata": {},
   "source": [
    "If you have downloaded the data from the Github repo, please unzip data.rar in the same directory before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d4c47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total file count: 4500\n"
     ]
    }
   ],
   "source": [
    "file_params=names_list(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f004b",
   "metadata": {},
   "source": [
    "### From the numpy array of the data captured, we will now create a consolidated feature array (from the numpy arrays) and labels array (from the filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2f664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features,labels=create_final_features(SAVE_PATH, file_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7430296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels for all data points in order are  ['ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'ascend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'descend', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'not ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'ok', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop', 'stop']\n"
     ]
    }
   ],
   "source": [
    "print('The labels for all data points in order are ',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da43846e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the final dataset:  (150, 30, 126)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the final dataset: ',features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94cb2a",
   "metadata": {},
   "source": [
    " ##### Final data shape:\n",
    " Actions - 5 <br>\n",
    " Samples /action - 30 <br>\n",
    " <b>Hence, total number of samples = 150</b> <br><br>\n",
    " \n",
    " Frames - 30  <- Total number of tokens <br>\n",
    " landmarks = 126 <- Length of each input token <br>\n",
    " <b> Features shape = (30,126) </b>\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6faba323",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SAVE_PATH=os.path.join(SAVE_PATH, 'final','final_features.npy')\n",
    "np.save(FINAL_SAVE_PATH,features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad315dc",
   "metadata": {},
   "source": [
    "### 2. Get label array of size (total sample size X no. of classes) - One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "333dc91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'ok', 1: 'descend', 2: 'ascend', 3: 'not ok', 4: 'stop'}\n",
      "{'ok': 0, 'descend': 1, 'ascend': 2, 'not ok': 3, 'stop': 4}\n"
     ]
    }
   ],
   "source": [
    "dict_labels, dict_reverse_labels=create_labels_dict(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "443efb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "ohk=OHK(labels,dict_reverse_labels)\n",
    "print(len(ohk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04297db",
   "metadata": {},
   "source": [
    "#### This is a super important step. When we are testing our final live video, we need to ensure that our labels map correctly to the One hot key encoding and hence to the output index provided for the labels dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ae56c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: ascend\tOHK:[0. 0. 1. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: descend\tOHK:[0. 1. 0. 0. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: not ok\tOHK:[0. 0. 0. 1. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: ok\tOHK:[1. 0. 0. 0. 0.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n",
      "Label: stop\tOHK:[0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for r in range(len(ohk)):\n",
    "    print(f'Label: {labels[r]}\\tOHK:{ohk[r]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013560f",
   "metadata": {},
   "source": [
    "Hence:<br>\n",
    "<ul>\n",
    "    <b>Action:&nbsp; &nbsp; One hot encoding</b>\n",
    "    <li>ascend:&nbsp; &nbsp; [0. 0. 0. 0. 1.]</li> \n",
    "    <li>not ok:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[0. 0. 0. 1. 0.]</li>\n",
    "    <li>descend:&nbsp;&nbsp;[0. 1. 0. 0. 0.]</li>\n",
    "    <li>stop:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[1. 0. 0. 0. 0.]</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d1981f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "ohk=np.array(ohk)\n",
    "print(ohk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efe85723",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(SAVE_PATH, 'final','final_labels.npy'),ohk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21195cc8",
   "metadata": {},
   "source": [
    "### 3. Shuffle and perform train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694e0810",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d7f31a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 3780)\n",
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test,y_train, y_test=train_test_extract(features, ohk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee9b6ff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (142, 30, 126)\n",
      "X_test shape: (8, 30, 126)\n",
      "y_train shape: (142, 5)\n",
      "y_test shape: (8, 5)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:',X_train.shape)\n",
    "print('X_test shape:',X_test.shape)\n",
    "print('y_train shape:',y_train.shape)\n",
    "print('y_test shape:',y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35109789",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(SAVE_PATH, 'final','X_train.npy'),X_train)\n",
    "np.save(os.path.join(SAVE_PATH, 'final','y_train.npy'),y_train)\n",
    "np.save(os.path.join(SAVE_PATH, 'final','X_test.npy'),X_test)\n",
    "np.save(os.path.join(SAVE_PATH, 'final','y_test.npy'),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ea0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
