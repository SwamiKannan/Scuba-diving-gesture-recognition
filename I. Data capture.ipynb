{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f02683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from data_capture import process_image\n",
    "from camera_utils import check_camera, check_hand_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c167d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_draw=mp.solutions.drawing_utils\n",
    "mp_style=mp.solutions.drawing_styles\n",
    "mp_hand=mp.solutions.hands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53d1f43",
   "metadata": {},
   "source": [
    "## A. Check if the utilities are working correctly before image capture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a6d6c8",
   "metadata": {},
   "source": [
    "### Check if camera is working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80e15e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_camera()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73933797",
   "metadata": {},
   "source": [
    "### Check the frames per second to determine speed of video capture\n",
    "We need to capture 1s of video for each sample. Since, cv2 and mediapipe work on capturing one frame, we need to determine how many frames make a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc10b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS of laptop cam is 30.0 fps\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "print('FPS of laptop cam is',cap.get(cv2.CAP_PROP_FPS), 'fps')\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd6412",
   "metadata": {},
   "source": [
    "### Check if mediapipe is correctly detecting landmarks in the hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa04416",
   "metadata": {},
   "outputs": [],
   "source": [
    "marks=check_hand_landmarks(mp_draw,mp_hand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6a9cf7",
   "metadata": {},
   "source": [
    "### Explore the landmarks captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e18f594f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of frames captured: 1\n",
      "No. of landmarks captured for the left hand: 21\n",
      "\n",
      "\n",
      "What does each landmark look like? \n",
      "x: 0.08354503661394119\n",
      "y: 0.7452123761177063\n",
      "z: 4.6253799723672273e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('No. of frames captured:', len(marks))\n",
    "print('No. of landmarks captured for the left hand:',len(marks[0].landmark))\n",
    "print('\\n')\n",
    "print(f'What does each landmark look like? \\n{marks[0].landmark[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e5bae0",
   "metadata": {},
   "source": [
    "<b> So mediapipe captures 21 points for each hand. Each of these 21 landmarks is described by their 3 coordinates </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2c414d",
   "metadata": {},
   "source": [
    "## B. Image Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f663b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions=['ascend', 'descend', 'ok', 'not ok','stop']\n",
    "samples=30\n",
    "frame_count=30 #30 frames per second will give us one second of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804454bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'data' not in os.listdir():\n",
    "    os.makedirs('data')\n",
    "SAVE_PATH=os.path.join('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c63d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_landmarks_dict=np.zeros((len(actions),samples,frame_count)) #store number of frames where no landmark was captured. Will help us understand if more actions need to be captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4727b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "act_dict={}\n",
    "\n",
    "with mp_hand.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():    \n",
    "        for a in actions:\n",
    "            for s in range(samples):\n",
    "                samples_array=[]\n",
    "                for f in range(frame_count):\n",
    "                    isframe, frame=cap.read()\n",
    "                    if f == 0:\n",
    "                        cv2.putText(frame, f'Action {a}, Sample {s}, Initiating...', (120,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                        cv2.imshow('Data', frame)\n",
    "                        cv2.waitKey(500)                      \n",
    "                        cv2.putText(frame, f'Action {a}, Sample {s}, Collecting....', (15,12),cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 1, cv2.LINE_AA)\n",
    "                        cv2.imshow('Data', frame)\n",
    "                    isframe, frame=cap.read()\n",
    "                    if isframe:\n",
    "                        name=a+'_'+str(s)+'_'+str(f)+'.npy'\n",
    "                        path=(os.path.join(SAVE_PATH,name))\n",
    "                        frame=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "                        frame,no_landmarks=process_image(path,frame,hands,mp_draw,mp_hand)\n",
    "                        no_landmarks_dict[actions.index(a),s,f]=no_landmarks\n",
    "                        frame=cv2.cvtColor(frame,cv2.COLOR_RGB2BGR)\n",
    "                        cv2.imshow('Data',frame) \n",
    "                    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()                        \n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75639f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
